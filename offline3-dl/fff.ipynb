{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rand = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        pass \n",
    "\n",
    "    def __call__(self,x):\n",
    "        pass \n",
    "\n",
    "    def backward(self,out_grad,learning_rate):\n",
    "        pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Layer):\n",
    "    def __init__(self,fan_in,fan_out,seed=42):\n",
    "        self.fan_in = fan_in \n",
    "        self.fan_out = fan_out\n",
    "\n",
    "        limit = np.sqrt(6 / (fan_in + fan_out))\n",
    "        self.weights = np.random.uniform(-limit, limit, size=(fan_out, fan_in))\n",
    "        # self.weights = np.random.randn(fan_out,fan_in)\n",
    "        self.bias = np.ones((fan_out,1))\n",
    "        # print(self.weights.shape)\n",
    "        # print(self.grad.shape)\n",
    "    def __call__(self,x):\n",
    "        self.input = x \n",
    "        return np.dot(self.weights,x.reshape(self.fan_in,-1)) + self.bias\n",
    "    \n",
    "\n",
    "    def __repr__(self):\n",
    "        pass \n",
    "\n",
    "    def backward(self, out_grad, learning_rate ):\n",
    "        wgrad = np.dot(out_grad, self.input.T) \n",
    "        bgrad = out_grad \n",
    "        inputgrad = np.dot(self.weights.T, out_grad)\n",
    "\n",
    "        self.weights -= learning_rate * wgrad \n",
    "        self.bias -= learning_rate * bgrad \n",
    "\n",
    "        # print(f\"{self.wgrad}\")\n",
    "        # print(f\"{self.bgrad}\")\n",
    "\n",
    "        return inputgrad \n",
    "\n",
    "    def reset_grad(self):\n",
    "        self.wgrad = np.zeros((self.fan_in,self.fan_out))\n",
    "        self.bgrad = np.zeros((1,self.fan_out)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(Layer):\n",
    "    def __call__(self, input):\n",
    "        self.input = input\n",
    "        tmp = input - max(input)  \n",
    "        tmp = np.exp(tmp)\n",
    "        self.output = tmp / np.sum(tmp)\n",
    "        return self.output \n",
    "    def backward(self, out_grad, learning_rate):\n",
    "        n = np.size(self.output) \n",
    "        return np.dot((np.identity(n)-self.output.T) * self.output, out_grad)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation(Layer):\n",
    "    def __init__(self,activation,activation_prime):\n",
    "        self.activation = activation \n",
    "        self.activation_grad = activation_prime\n",
    "\n",
    "    def __call__(self, input):\n",
    "        self.input = input \n",
    "        return self.activation(self.input) \n",
    "    \n",
    "    def backward(self, out_grad, learning_rate):\n",
    "        return np.multiply(out_grad, self.activation_grad(self.input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh(Activation):\n",
    "    def __init__(self):\n",
    "        def tanh(x):\n",
    "            return np.tanh(x)\n",
    "        def tanh_grad(x):\n",
    "            return 1-np.tanh(x)**2 \n",
    "        super().__init__(tanh,tanh_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Activation):\n",
    "    def __init__(self):\n",
    "        def sigmoid(x):\n",
    "            return 1.0 / (1.0 + np.exp(-x))\n",
    "        \n",
    "        def sigmoid_grad(x):\n",
    "            return sigmoid(x) * (1.0 - sigmoid(x)) \n",
    "        super().__init__(sigmoid,sigmoid_grad) \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Activation):\n",
    "    def __init__(self):\n",
    "        def relu(x):\n",
    "            return np.maximum(0,x)\n",
    "        def relu_grad(x):\n",
    "            return np.where(x > 0, 1, np.where(x < 0, 0, 0.5))\n",
    "        super().__init__(relu,relu_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(Layer):\n",
    "    def __init__(self, dropout_rate):\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.mask = None\n",
    "\n",
    "    def __call__(self, x, training=False):\n",
    "        if training:\n",
    "            self.mask = (np.random.rand(*x.shape) < (1 - self.dropout_rate)) / (1 - self.dropout_rate)\n",
    "            # print(self.mask)\n",
    "            return x * self.mask\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def backward(self, grad):\n",
    "        return grad * self.mask if self.mask is not None else grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true - y_pred, 2))\n",
    "\n",
    "def mse_grad(y_true, y_pred):\n",
    "    return 2 * (y_pred - y_true) / np.size(y_true)\n",
    "\n",
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    return np.mean(-y_true * np.log(y_pred) - (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "def binary_cross_entropy_grad(y_true, y_pred): # wrt y_pred\n",
    "    return ((1 - y_true) / (1 - y_pred) - y_true / y_pred) / np.size(y_true)\n",
    "\n",
    "def cross_entropy(y_true,y_pred):\n",
    "    return np.mean(-y_true*np.log(y_pred)) \n",
    "\n",
    "def cross_entropy_grad(y_true,y_pred):\n",
    "    return np.mean(-y_true/y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, *layers):\n",
    "        self.layers = [] \n",
    "        for layer in layers:\n",
    "            self.layers += [layer]\n",
    "        \n",
    "    def __call__(self,input):\n",
    "        for layer in self.layers:\n",
    "            input = layer(input)\n",
    "        return input \n",
    "    def save(self,filename):\n",
    "        pass \n",
    "    def load(self,filename):\n",
    "        pass\n",
    "    \n",
    "    def train_minibatch(self,):\n",
    "        pass \n",
    "    \n",
    "    def train_batch(self, loss, loss_grad, X, y, epochs = 1000, learning_rate = 0.001, verbose=True):\n",
    "        for epoch in range(epochs):\n",
    "            error = 0 \n",
    "            for x, y in zip(X,y):\n",
    "                output = self.__call__(self,x)\n",
    "                error += loss(y,output)\n",
    "\n",
    "                grad = loss_grad(y,output)\n",
    "\n",
    "                for layer in reversed(self.layers):\n",
    "                    grad = layer.backward(grad, learning_rate)\n",
    "            error /= len(X)\n",
    "            if verbose:\n",
    "                print(f\"{epoch=}, {error=}\")\n",
    "\n",
    "    def eval(self, loss, X,y):\n",
    "        error = 0 \n",
    "        for x,y in zip(X,y):\n",
    "            output = self.__call__(self,x)\n",
    "            error += loss(y,output)\n",
    "        error /= len(X)\n",
    "        return error \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.77395605]\n",
      " [0.43887844]\n",
      " [0.85859792]\n",
      " [0.69736803]\n",
      " [0.09417735]\n",
      " [0.97562235]\n",
      " [0.7611397 ]\n",
      " [0.78606431]\n",
      " [0.12811363]\n",
      " [0.45038594]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.1491558 ],\n",
       "       [0.22285238],\n",
       "       [0.25821857],\n",
       "       [0.26527804],\n",
       "       [0.10449521]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin = Linear(10,5)\n",
    "relu = ReLU() \n",
    "sigmoid = Sigmoid()\n",
    "softmax = Softmax()\n",
    "\n",
    "model = NN(lin, sigmoid, relu, softmax) \n",
    "\n",
    "x = rand.random(10).reshape(-1,1)\n",
    "\n",
    "print(x)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5306864   1.59314176  2.00005323  0.32641984  1.1931023   0.5481565\n",
      "   0.429037   -0.33640329  0.91954891  0.40844161  0.16845908 -1.34799869\n",
      "   1.00846121  0.573484   -1.50532525  0.82257466  0.31869984 -0.35581409\n",
      "  -2.02165578  0.11128437 -1.33786852  0.01399539 -0.36155983 -0.82571222\n",
      "   0.84308082  0.15730206 -1.63736037 -1.06320412  0.30038575 -1.56543225\n",
      "   0.01121587 -0.34955071]]\n",
      "[[9.99883685e-09]\n",
      " [1.74438509e-04]\n",
      " [8.64152200e-10]\n",
      " [6.40567144e-05]\n",
      " [3.02823232e-08]\n",
      " [1.47757057e-08]\n",
      " [9.91997588e-16]\n",
      " [9.99018038e-01]\n",
      " [7.43362000e-04]\n",
      " [4.85393448e-08]] 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "model = NN(Linear(32,5), ReLU(), Linear(5,10), Softmax()) \n",
    "\n",
    "x = np.random.randn(1,32)\n",
    "\n",
    "print(x)\n",
    "result = model(x) \n",
    "print(result, np.sum(result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms \n",
    "\n",
    "train_validation_dataset = datasets.EMNIST(root='./data', \n",
    "                                           split='letters',\n",
    "                                           train=True,\n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True,\n",
    "                                        )\n",
    "\n",
    "\n",
    "independent_test_dataset = datasets.EMNIST(\n",
    "                             root='./data',\n",
    "                             split='letters',\n",
    "                             train=False,\n",
    "                             transform=transforms.ToTensor(),\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_validation_dataset)\n",
    "train_validation_dataset.data.reshape(-1,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame(train_validation_dataset.data.reshape(-1,28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  774  775  776  777  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "\n",
       "   778  779  780  781  782  783  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(Linear(28, 26), Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(28,1)\n",
    "x\n",
    "drop = Dropout(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ],\n",
       "       [-0.        ],\n",
       "       [-0.        ],\n",
       "       [-0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [-0.        ],\n",
       "       [-0.        ],\n",
       "       [-2.47025895],\n",
       "       [ 0.        ],\n",
       "       [-0.        ],\n",
       "       [-0.        ],\n",
       "       [-5.12283294],\n",
       "       [ 0.        ],\n",
       "       [-0.        ],\n",
       "       [-0.        ],\n",
       "       [-0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [-0.        ],\n",
       "       [-0.        ],\n",
       "       [ 0.        ],\n",
       "       [-0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [-0.        ],\n",
       "       [-3.1709267 ],\n",
       "       [-0.        ]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop(x, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
