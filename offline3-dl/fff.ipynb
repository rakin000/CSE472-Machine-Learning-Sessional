{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rand = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        pass \n",
    "\n",
    "    def __call__(self,x,train=False):\n",
    "        pass \n",
    "\n",
    "    def backward(self,out_grad,learning_rate):\n",
    "        pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Layer):\n",
    "    def __init__(self,fan_in,fan_out,seed=42):\n",
    "        self.fan_in = fan_in \n",
    "        self.fan_out = fan_out\n",
    "\n",
    "        limit = np.sqrt(6 / (fan_in + fan_out))\n",
    "        self.weights = np.random.uniform(-limit, limit, size=(fan_out, fan_in))\n",
    "        # self.weights = np.random.randn(fan_out,fan_in)\n",
    "        self.bias = np.ones((fan_out,1))\n",
    "        # print(self.weights.shape)\n",
    "        # print(self.grad.shape)\n",
    "    def __call__(self,x,train=False):\n",
    "        self.input = x.reshape(self.fan_in,-1)\n",
    "        return np.dot(self.weights,self.input) + self.bias\n",
    "    \n",
    "\n",
    "    def __repr__(self):\n",
    "        pass \n",
    "\n",
    "    def backward(self, out_grad, learning_rate ):\n",
    "        wgrad = np.dot(out_grad, self.input.T) \n",
    "        bgrad = out_grad \n",
    "        inputgrad = np.dot(self.weights.T, out_grad)\n",
    "\n",
    "        self.weights -= learning_rate * wgrad \n",
    "        self.bias -= learning_rate * bgrad \n",
    "\n",
    "        # print(f\"{self.wgrad}\")\n",
    "        # print(f\"{self.bgrad}\")\n",
    "\n",
    "        return inputgrad \n",
    "\n",
    "    def reset_grad(self):\n",
    "        self.wgrad = np.zeros((self.fan_in,self.fan_out))\n",
    "        self.bgrad = np.zeros((1,self.fan_out)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(Layer):\n",
    "    def __call__(self, input, train=False):\n",
    "        self.input = input\n",
    "        tmp = input - max(input)  \n",
    "        tmp = np.exp(tmp)\n",
    "        self.output = tmp / np.sum(tmp)\n",
    "        return self.output \n",
    "    def backward(self, out_grad, learning_rate):\n",
    "        n = np.size(self.output) \n",
    "        return np.dot((np.identity(n)-self.output.T) * self.output, out_grad)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation(Layer):\n",
    "    def __init__(self,activation,activation_prime):\n",
    "        self.activation = activation \n",
    "        self.activation_grad = activation_prime\n",
    "\n",
    "    def __call__(self, input, train=False):\n",
    "        self.input = input \n",
    "        return self.activation(self.input) \n",
    "    \n",
    "    def backward(self, out_grad, learning_rate):\n",
    "        return np.multiply(out_grad, self.activation_grad(self.input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh(Activation):\n",
    "    def __init__(self):\n",
    "        def tanh(x):\n",
    "            return np.tanh(x)\n",
    "        def tanh_grad(x):\n",
    "            return 1-np.tanh(x)**2 \n",
    "        super().__init__(tanh,tanh_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Activation):\n",
    "    def __init__(self):\n",
    "        def sigmoid(x):\n",
    "            return 1.0 / (1.0 + np.exp(-x))\n",
    "        \n",
    "        def sigmoid_grad(x):\n",
    "            return sigmoid(x) * (1.0 - sigmoid(x)) \n",
    "        super().__init__(sigmoid,sigmoid_grad) \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Activation):\n",
    "    def __init__(self):\n",
    "        def relu(x):\n",
    "            return np.maximum(0,x)\n",
    "        def relu_grad(x):\n",
    "            return np.where(x > 0, 1, np.where(x < 0, 0, 0.5))\n",
    "        super().__init__(relu,relu_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(Layer):\n",
    "    def __init__(self, dropout_rate):\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.mask = None\n",
    "\n",
    "    def __call__(self, x, train=False):\n",
    "        if train:\n",
    "            self.mask = (np.random.rand(*x.shape) < (1 - self.dropout_rate)) / (1 - self.dropout_rate)\n",
    "            # print(self.mask)\n",
    "            return x * self.mask\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def backward(self, grad, learning_rate):\n",
    "        return grad * self.mask if self.mask is not None else grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true - y_pred, 2))\n",
    "\n",
    "def mse_grad(y_true, y_pred):\n",
    "    return 2 * (y_pred - y_true) / np.size(y_true)\n",
    "\n",
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    return np.mean(-y_true * np.log(y_pred) - (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "def binary_cross_entropy_grad(y_true, y_pred): # wrt y_pred\n",
    "    return ((1 - y_true) / (1 - y_pred) - y_true / y_pred) / np.size(y_true)\n",
    "\n",
    "def cross_entropy(y_true,y_pred):\n",
    "    return np.mean(-y_true*np.log(y_pred)) \n",
    "\n",
    "def cross_entropy_grad(y_true,y_pred):\n",
    "    return np.mean(-y_true/y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, *layers):\n",
    "        self.layers : Layer = [] \n",
    "        for layer in layers:\n",
    "            self.layers += [layer]\n",
    "        \n",
    "    def __call__(self,input,train=False):\n",
    "        for layer in self.layers:\n",
    "            input = layer(input,train=train)\n",
    "        return input \n",
    "    def backward(self, ):\n",
    "        pass \n",
    "    \n",
    "    def save(self,filename):\n",
    "        pass \n",
    "    def load(self,filename):\n",
    "        pass\n",
    "    \n",
    "    def train_minibatch(self,):\n",
    "        pass \n",
    "    \n",
    "    def train_batch(self, loss, loss_grad, X, y, epochs = 1000, learning_rate = 0.001, verbose=True):\n",
    "        for epoch in range(epochs):\n",
    "            error = 0 \n",
    "            for x, y in zip(X,y):\n",
    "                output = self.__call__(x,train=True)\n",
    "                error += loss(y,output)\n",
    "\n",
    "                grad = loss_grad(y,output)\n",
    "\n",
    "                for layer in reversed(self.layers):\n",
    "                    grad = layer.backward(grad, learning_rate)\n",
    "            error /= len(X)\n",
    "            if verbose:\n",
    "                print(f\"{epoch=}, {error=}\")\n",
    "\n",
    "    def eval(self, loss, X,y):\n",
    "        error = 0 \n",
    "        for x,y in zip(X,y):\n",
    "            output = self.__call__(x)\n",
    "            error += loss(y,output)\n",
    "        error /= len(X)\n",
    "        return error \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.77395605]\n",
      " [0.43887844]\n",
      " [0.85859792]\n",
      " [0.69736803]\n",
      " [0.09417735]\n",
      " [0.97562235]\n",
      " [0.7611397 ]\n",
      " [0.78606431]\n",
      " [0.12811363]\n",
      " [0.45038594]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.19428353],\n",
       "       [0.24264922],\n",
       "       [0.22592517],\n",
       "       [0.14571562],\n",
       "       [0.19142646]])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin = Linear(10,5)\n",
    "relu = ReLU() \n",
    "sigmoid = Sigmoid()\n",
    "softmax = Softmax()\n",
    "\n",
    "model = NN(lin, sigmoid, relu, softmax) \n",
    "\n",
    "x = rand.random(10).reshape(-1,1)\n",
    "\n",
    "print(x)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12145991  0.13581939  1.07936877 -0.02456193 -1.4789741  -0.1496096\n",
      "   0.45248678  2.18440467 -0.94909598  0.96902005 -0.27567245  0.29392967\n",
      "  -0.20771191  0.92493014 -0.05235155  0.67805099  2.01729155 -0.9919856\n",
      "  -0.04054623  0.01893221 -0.33492212 -0.43392444 -1.36067623 -0.72886045\n",
      "   0.04237201  0.09486662 -0.8063684   0.28603057 -1.7058329  -0.92626847\n",
      "  -1.04479309 -0.89894544]]\n",
      "[[0.10411696]\n",
      " [0.4448591 ]\n",
      " [0.1441088 ]\n",
      " [0.01760836]\n",
      " [0.1479912 ]\n",
      " [0.00629213]\n",
      " [0.02052927]\n",
      " [0.04333672]\n",
      " [0.06622795]\n",
      " [0.00492951]] 1.0\n"
     ]
    }
   ],
   "source": [
    "model = NN(Linear(32,5), ReLU(), Linear(5,10), Softmax()) \n",
    "\n",
    "x = np.random.randn(1,32)\n",
    "\n",
    "print(x)\n",
    "result = model(x) \n",
    "print(result, np.sum(result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms \n",
    "\n",
    "train_validation_dataset = datasets.EMNIST(root='./data', \n",
    "                                           split='letters',\n",
    "                                           train=True,\n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True,\n",
    "                                        )\n",
    "\n",
    "\n",
    "independent_test_dataset = datasets.EMNIST(\n",
    "                             root='./data',\n",
    "                             split='letters',\n",
    "                             train=False,\n",
    "                             transform=transforms.ToTensor(),\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124800"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_validation_dataset.target_transform\n",
    "train_validation_dataset.targets\n",
    "len(train_validation_dataset.data)\n",
    "len(train_validation_dataset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_validation_dataset)\n",
    "n_classes = len(train_validation_dataset.classes)\n",
    "n_datapoints = len(train_validation_dataset.targets)\n",
    "\n",
    "X_train = np.array(train_validation_dataset.data.reshape(-1,28*28))\n",
    "# y_train = np.zeros((len(train_validation_dataset.targets),len(train_validation_dataset.classes)))\n",
    "\n",
    "y_train = np.array([[1 if temp == i else 0 for i in range(n_classes)] for temp in train_validation_dataset.targets])\n",
    "y_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_validation_dataset.targets[1]\n",
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(independent_test_dataset.data.reshape(-1,28*28))\n",
    "y_test = np.array([[1 if temp == i else 0 for i in range(n_classes)] for temp in independent_test_dataset.targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame(train_validation_dataset.data.reshape(-1,28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  774  775  776  777  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "\n",
       "   778  779  780  781  782  783  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(Linear(28, 26), Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(28,1)\n",
    "x\n",
    "drop = Dropout(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.7771404 ],\n",
       "       [-0.        ],\n",
       "       [ 0.        ],\n",
       "       [-0.        ],\n",
       "       [-0.        ],\n",
       "       [-0.        ],\n",
       "       [-9.33086507],\n",
       "       [-0.        ],\n",
       "       [-0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [-0.        ],\n",
       "       [ 0.        ],\n",
       "       [-0.        ],\n",
       "       [-0.        ],\n",
       "       [-0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [-0.        ],\n",
       "       [ 0.        ],\n",
       "       [-0.        ],\n",
       "       [-0.        ],\n",
       "       [-0.        ],\n",
       "       [-4.97264438],\n",
       "       [ 0.        ],\n",
       "       [-0.        ]])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop(x, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(Linear(28*28,1024), ReLU(), Dropout(0.2), Linear(1024,26), ReLU(), Dropout(0.3), Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_batch(cross_entropy, cross_entropy_grad, X_train, y_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
